{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stanko_Diego_ejercicio2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlyDMSFo+5+fK9H7aMBWaN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StankoDiego/SOA_EA_2/blob/main/HPC/Stanko_Diego_ejercicio2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7j9ao2B9c4E"
      },
      "source": [
        "#1. Introducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_LN6fDhz3BQ"
      },
      "source": [
        "Se va a implementar un algoritmo para resolver la suma de matrices de dimension N*N. \n",
        "\n",
        "Se implementaran dos algoritmos, uno ejecuta y resuelve el calculo de manera secuencial sobre el mismo procesador y el segundo implementa la suma de los terminos de la matriz de forma paralela utilizando GPU. Para esto se implementan hilos en dos dimensiones, a partir de un calulo en el kernel podemos acceder a cada elemento de la matriz para poder realizar la operacion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r05bRE1N0mW2"
      },
      "source": [
        "#1.1 Explicación del algoritmo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fWAC6IA1EpI"
      },
      "source": [
        "La suma de matrices[1] es una operación lineal que consiste en unificar los elementos de dos o más matrices que coincidan en posición dentro de sus respectivas matrices y que estas tengan el mismo orden.\n",
        "\n",
        "En otras palabras, el sumatorio de una o más matrices es la unión de los elementos que tengan la misma posición dentro de las matrices y que estas tengan el mismo orden.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=16M9RJRRsQELQqiC15qRqNC_bdQBfMc1_)\n",
        "\n",
        "Para sumar dos matrices se debe verificar que el orden de estas sean iguales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnpRzgg9kTb"
      },
      "source": [
        "#2. Armado del ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4z5eBuU9pRy"
      },
      "source": [
        "##2.1 Armado del ambiente en CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dDFvvnVFEQI"
      },
      "source": [
        "No se requiere la ejecucion previa de algun comando"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCdvhcwu9vXy"
      },
      "source": [
        "##2.1 Armado del ambiente en GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SUH5e0UsqT-"
      },
      "source": [
        "1. Ir a Entornto de ejecucion -> Cambiar tipo de entorno de ejecucion y seleccionar la opcion GPU.\n",
        "2. Se requiere la instalación del modulo de Cuda para Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JspUFpTXjjFC"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUCDxn8-9ywT"
      },
      "source": [
        "#3. Desarrollo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDJ5YrXp91Jy"
      },
      "source": [
        "##3.1 Desarrollo en CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnWXJbo6BePp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "322d0860-52c0-4216-ea2d-70ad0b6543b9"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "tamMatriz =  10#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "import numpy\n",
        "import time\n",
        "import sys\n",
        "\n",
        "tiempoTotal = time.time() * 1000\n",
        "try: \n",
        "  matriz_A = numpy.random.randint(5000, size=(tamMatriz, tamMatriz))\n",
        "  matriz_A = matriz_A.astype(numpy.int32())\n",
        "  matriz_B = numpy.random.randint(5000, size=(tamMatriz, tamMatriz))\n",
        "  matriz_B = matriz_B.astype(numpy.int32())\n",
        "except Exception:\n",
        "  sys.exit(\"El tamaño no puede ser negativo\")\n",
        "\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Matriz A:\\n\",matriz_A)\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Matriz B:\\n\",matriz_B)\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "tiempoBucle = time.time() * 1000\n",
        "matriz_R = numpy.zeros((tamMatriz, tamMatriz))  \n",
        "matriz_R = matriz_R.astype(numpy.int32())\n",
        "\n",
        "for i in range (0, tamMatriz):\n",
        "  for j in range(0, tamMatriz):\n",
        "    matriz_R[i][j] = matriz_A[i][j] + matriz_B[i][j]\n",
        "\n",
        "print(\"Matriz R:\\n\",matriz_R)\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "tiempoTotal = (time.time() * 1000) - tiempoTotal\n",
        "tiempoBucle = (time.time() * 1000) - tiempoBucle\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"Tiempo del bucle: \" , tiempoBucle , \"[ms.]\")\n",
        "print(\"Tiempo del total: \" , tiempoTotal , \"[ms.]\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------\n",
            "Matriz A:\n",
            " [[1234  250  498 4289 3438 1595 1738  386 1877  639]\n",
            " [3656 2748 2210   54 2575 2334 3615  815 4198 3503]\n",
            " [3777 3272  465  104  749 3364 2714  417  543  819]\n",
            " [2015 2100 1414 2784 1017   48 2281 3934 3837 4269]\n",
            " [4471 2161 3631 3470 1381 3899 3003 3201 1837 2585]\n",
            " [4920 1359 2782 3162 2115 1822 1414 3711 1613  530]\n",
            " [1788 4815 1373 4685 2532 4392 4507 1561  458 1296]\n",
            " [1613 2870 2980 4158  299 3825 2459 1068 4758 1121]\n",
            " [2642  893 3147  717 4266 4582 1353 1227 1918  358]\n",
            " [2760 1105 4032 3488  569 2386 1545 1880 4149 2420]]\n",
            "---------------------------------------------------\n",
            "Matriz B:\n",
            " [[2927  665 4550 2506 1749 4540 2707 1446 3662 4998]\n",
            " [2935 4248  121 4965 2003 3509 4631 3982 1613 2598]\n",
            " [ 894  696 1758 4161 3646   93 4475 1242 4451  633]\n",
            " [3568 1872 3920 1638 3204 3084 2250 3422 4283 4454]\n",
            " [ 789   76 1022 4438  394 1214 3533 3365 3251 1299]\n",
            " [1679 1781 3426  624 1571  993 1885 3561 1430 3852]\n",
            " [1610 3911 1069  169  914  977  909 3096 3071 4743]\n",
            " [1239 1383 4773 2126 1593  160 1782 4808 1365 4979]\n",
            " [  97  568 1295 2681 4336 4043  828 1072 3562  224]\n",
            " [2813 4200  611  395 3946 3164 4405  898 1019 2715]]\n",
            "---------------------------------------------------\n",
            "Matriz R:\n",
            " [[4161  915 5048 6795 5187 6135 4445 1832 5539 5637]\n",
            " [6591 6996 2331 5019 4578 5843 8246 4797 5811 6101]\n",
            " [4671 3968 2223 4265 4395 3457 7189 1659 4994 1452]\n",
            " [5583 3972 5334 4422 4221 3132 4531 7356 8120 8723]\n",
            " [5260 2237 4653 7908 1775 5113 6536 6566 5088 3884]\n",
            " [6599 3140 6208 3786 3686 2815 3299 7272 3043 4382]\n",
            " [3398 8726 2442 4854 3446 5369 5416 4657 3529 6039]\n",
            " [2852 4253 7753 6284 1892 3985 4241 5876 6123 6100]\n",
            " [2739 1461 4442 3398 8602 8625 2181 2299 5480  582]\n",
            " [5573 5305 4643 3883 4515 5550 5950 2778 5168 5135]]\n",
            "---------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Tiempo del bucle:  0.758056640625 [ms.]\n",
            "Tiempo del total:  1.993408203125 [ms.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvdUxO9d93Xa"
      },
      "source": [
        "##3.2 Desarrollo en GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brL5K2Qjjpoo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a913cb-a80f-44fb-900e-c3d1388fec29"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "tamMatriz =  10#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "import time\n",
        "\n",
        "import numpy\n",
        "import sys\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "tiempoTotal = (time.time()*1000)\n",
        "\n",
        "try: \n",
        "  matriz_A_cpu = numpy.random.randint(5000, size=(tamMatriz, tamMatriz))\n",
        "  matriz_A_cpu = matriz_A_cpu.astype(numpy.int32())\n",
        "  matriz_B_cpu = numpy.random.randint(5000, size=(tamMatriz, tamMatriz))\n",
        "  matriz_B_cpu = matriz_B_cpu.astype(numpy.int32())\n",
        "except Exception:\n",
        "  sys.exit(\"El tamaño de la matriz no puede ser negativo\")\n",
        "\n",
        "try:  \n",
        "  matriz_R_cpu = numpy.zeros((tamMatriz, tamMatriz)) \n",
        "  matriz_R_cpu = matriz_R_cpu.astype(numpy.int32()) \n",
        "  matriz_A_gpu = cuda.mem_alloc(matriz_A_cpu.nbytes)\n",
        "  matriz_B_gpu = cuda.mem_alloc(matriz_B_cpu.nbytes)\n",
        "  matriz_R_gpu = cuda.mem_alloc(matriz_R_cpu.nbytes)\n",
        "  cuda.memcpy_htod(matriz_A_gpu, matriz_A_cpu)\n",
        "  cuda.memcpy_htod(matriz_B_gpu, matriz_B_cpu)\n",
        "  cuda.memcpy_htod(matriz_R_gpu, matriz_R_cpu)\n",
        "except Exception:\n",
        "  sys.exit(\"Error de asignacion de memoria para gpu\")\n",
        "\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Matriz A:\\n\",matriz_A_cpu)\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Matriz B:\\n\",matriz_B_cpu)\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void matrixMultiplicationKernel(float* A, float* B, float* R,\n",
        "                                           int N\n",
        "                                           ) {\n",
        "\n",
        "    int x = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "    int y = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\n",
        "    if(y < N){\n",
        "      R[x+ y*N] = A[x+ y*N]  +  B[x+ y*N];\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "kernel = module.get_function(\"matrixMultiplicationKernel\")\n",
        "\n",
        "dim_hilo_x = 16\n",
        "dim_bloque_x = numpy.int( (tamMatriz + dim_hilo_x-1) / dim_hilo_x )\n",
        "\n",
        "dim_hilo_y = 16\n",
        "dim_bloque_y = numpy.int( (tamMatriz + dim_hilo_y-1) / dim_hilo_y )\n",
        "\n",
        "print( \"Thread: [\", dim_hilo_x, \",\", dim_hilo_y, \" ], Bloque : [\", dim_bloque_x, \",\", dim_bloque_y, \"]\" )\n",
        "print( \"Total de Thread: [\", dim_hilo_x*dim_bloque_x, \",\", dim_hilo_y*dim_bloque_y, \" ]\", \" = \", dim_hilo_x*dim_bloque_x*dim_hilo_y*dim_bloque_y )\n",
        "\n",
        "tiempo_kernel = time.time() * 1000\n",
        "\n",
        "kernel(matriz_A_gpu, matriz_B_gpu, matriz_R_gpu,\n",
        "       numpy.int32(tamMatriz),        \n",
        "       block=( dim_hilo_x, dim_hilo_y, 1), \n",
        "       grid=(dim_bloque_x, dim_bloque_y,1)\n",
        "       )\n",
        "\n",
        "tiempo_kernel = (time.time() *1000) - tiempo_kernel\n",
        "\n",
        "cuda.memcpy_dtoh(matriz_R_cpu, matriz_R_gpu)\n",
        "tiempoTotal = (time.time() * 1000) - tiempoTotal\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Matriz resultado:\\n\",matriz_R_cpu)\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Tiempo TOTAL: \", tiempoTotal, \"[ms]\" )\n",
        "print(\"Tiempo GPU  : \", tiempo_kernel, \"[ms]\" )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------\n",
            "Matriz A:\n",
            " [[3565 2369  943  776 1778 2033  498  644  202 1480]\n",
            " [2768 1323 3031 1903   74 1196  297 3883 1249 2559]\n",
            " [3564  144 4847 2429  994  665  832 1380 1833   86]\n",
            " [ 144 2186 2149 1153 2321  393 4898 2295  179  674]\n",
            " [ 396 3655 3741 2874 4252 4328 2310 1802 4455 4578]\n",
            " [ 654 4504  218 1441  421 1068 3725 1321  467  332]\n",
            " [2110 4618 1118 4602  469 3049 3016 4593 2313 4209]\n",
            " [ 180 4340 2683  758 3473 1833 3906 4074 1956 2684]\n",
            " [4808 3670 4097 4023  166 2953 3512 2153  615  333]\n",
            " [3326 3281  345 4201 2403 1367 1821 4507  742  967]]\n",
            "---------------------------------------------------\n",
            "Matriz B:\n",
            " [[ 193 4781 3764  929 2630 2128  263 3311 1367 3716]\n",
            " [ 956 4786 3858 1004 2219  612 3856 3675 3357  588]\n",
            " [2742 2183 3215  769 3853  627 1306  871 2288 1677]\n",
            " [2597 1394 3730 2295  385 2584 1012 2008  138 3286]\n",
            " [1857 1176 3805  432 3021 3878 1155 4481 2228 4515]\n",
            " [1694 1686  444 1478 3476 3700 4949  246 2407 1379]\n",
            " [1582 3441 4729 2670 1109 3015 2447 3559 3787 3520]\n",
            " [1099 4736 3794 3432 1125 3973 3505 2678 3285  854]\n",
            " [2189  639  354  684 2686  910 4319 2633 2626  738]\n",
            " [2521 4727 3220 1709 2311  682 2551 3770 2457  836]]\n",
            "---------------------------------------------------\n",
            "Thread: [ 16 , 16  ], Bloque : [ 1 , 1 ]\n",
            "Total de Thread: [ 16 , 16  ]  =  256\n",
            "---------------------------------------------------\n",
            "Matriz resultado:\n",
            " [[3758 7150 4707 1705 4408 4161  761 3955 1569 5196]\n",
            " [3724 6109 6889 2907 2293 1808 4153 7558 4606 3147]\n",
            " [6306 2327 8062 3198 4847 1292 2138 2251 4121 1763]\n",
            " [2741 3580 5879 3448 2706 2977 5910 4303  317 3960]\n",
            " [2253 4831 7546 3306 7273 8206 3465 6283 6683 9093]\n",
            " [2348 6190  662 2919 3897 4768 8674 1567 2874 1711]\n",
            " [3692 8059 5847 7272 1578 6064 5463 8152 6100 7729]\n",
            " [1279 9076 6477 4190 4598 5806 7411 6752 5241 3538]\n",
            " [6997 4309 4451 4707 2852 3863 7831 4786 3241 1071]\n",
            " [5847 8008 3565 5910 4714 2049 4372 8277 3199 1803]]\n",
            "---------------------------------------------------\n",
            "Tiempo TOTAL:  6.4736328125 [ms]\n",
            "Tiempo GPU  :  0.139404296875 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftAKsvjH953S"
      },
      "source": [
        "#4. Tabla de pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncs8MsOX9_yz"
      },
      "source": [
        "##4.1 Tabla de pasos CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBfp6RFobcGJ"
      },
      "source": [
        "Tabla de ejecucion de forma secuencial\n",
        ">Procesador | Funcion | Detalle\n",
        ">--- | --- | ----\n",
        ">CPU\t|@param              |Lectura del tamaño de matriz.\n",
        ">CPU\t|import              |Se importa los diferentes modulos a utilizar.\n",
        ">CPU\t|tiempoTotal         |Se obtiene el tiempo actual para futuras mediciones.\n",
        ">CPU\t|numpy.random.randint|Inicializacion de matrices.\n",
        ">CPU\t|tiempoBucle\t       |Se toma el tiempo inicial del algoritmo presentado.\n",
        ">CPU\t|for…\tfor            |Se realiza el algoritmo.\n",
        ">CPU\t|tiempoBucle\t       |Toma el tiempo final del algoritmo presentado.\n",
        ">CPU\t|tiempoTotal\t       |Toma el tiempo final de la ejecucion.\n",
        ">CPU\t|print()\t           |Se informan los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAtzQqbF-FGT"
      },
      "source": [
        "##4.1 Tabla de pasos GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJGwWEidbdqT"
      },
      "source": [
        "Tabla de ejecucion en multiples hilos de ejecucion\n",
        ">Procesador | Funcion | Detalle\n",
        ">--- | --- | ----\n",
        ">CPU\t|@param              |Lectura del tamaño de matriz.\n",
        ">CPU\t|import              |Se importa los diferentes modulos a utilizar.\n",
        ">CPU\t|tiempoTotal         |Se obtiene el tiempo actual para futuras mediciones.\n",
        ">CPU\t|numpy.random.randint|Inicializacion de matrices.\n",
        ">CPU\t|numpy.zeros         |Inicializacion de matriz de resultado.\n",
        ">**GPU**  |cuda.mem_alloc        |Reserva de memoria de GPU.\n",
        ">**GPU**  |cuda.memcpy_htod      |Copia de memoria de CPU a GPU.\n",
        ">CPU\t|SourceModule        |Definición de código del kernel.\n",
        ">CPU\t|module.get_function        |Generación de función del Kernel de GPU.\n",
        ">CPU\t|dim_hilo_x, dim_hilo_y\t    | Calcula las dimensiones para la ejecuciòn de 2D.\n",
        ">CPU\t|tiempo_kernel\t       |Toma el tiempo inicial del algoritmo presentado.\n",
        ">**GPU**\t|kernel()            |Ejecución del kernel\n",
        ">CPU\t|tiempo_kernel\t       |Toma el tiempo final del algoritmo presentado.\n",
        ">CPU\t|tiempoTotal\t       |Toma el tiempo final de la ejecucion.\n",
        ">CPU\t|print()\t           |Se informan los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDk8h3X0-I2C"
      },
      "source": [
        "#5. Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1IpZ52s6X_I"
      },
      "source": [
        "El algoritmo no presenta mucha dificultad, lo interesante es que el primer algoritmo posee una complejidad O(N^2) y su rendimiento empeorara a medida que las dimensiones de la matriz sean mayores. Con la implementación paralela aumenta la eficiencia frente a la ejecución secuencial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0xYuckC1342"
      },
      "source": [
        "#6. Bibliografía"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au-dr5c116eU"
      },
      "source": [
        "[1].Suma de matrices [matrices](https://economipedia.com/definiciones/suma-de-matrices.html)"
      ]
    }
  ]
}