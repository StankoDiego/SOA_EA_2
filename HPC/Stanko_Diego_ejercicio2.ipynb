{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stanko_Diego_ejercicio2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMiPWVsQlRzgjuRusme+sRB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StankoDiego/SOA_EA_2/blob/main/HPC/Stanko_Diego_ejercicio2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7j9ao2B9c4E"
      },
      "source": [
        "#1. Introducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_LN6fDhz3BQ"
      },
      "source": [
        "Se va a implementar un algoritmo para resolver la suma de matrices de dimension N*N. \n",
        "\n",
        "Se implementaran dos algoritmos, uno ejecuta y resuelve el calculo de manera secuencial sobre el mismo procesador y el segundo implementa la suma de los terminos de la matriz de forma paralela utilizando GPU. Para esto se implementan hilos en dos dimensiones, a partir de un calulo en el kernel podemos acceder a cada elemento de la matriz para poder realizar la operacion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r05bRE1N0mW2"
      },
      "source": [
        "#1.1 Explicación del algoritmo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fWAC6IA1EpI"
      },
      "source": [
        "La suma de matrices[1] es una operación lineal que consiste en unificar los elementos de dos o más matrices que coincidan en posición dentro de sus respectivas matrices y que estas tengan el mismo orden.\n",
        "\n",
        "En otras palabras, el sumatorio de una o más matrices es la unión de los elementos que tengan la misma posición dentro de las matrices y que estas tengan el mismo orden.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=16M9RJRRsQELQqiC15qRqNC_bdQBfMc1_)\n",
        "\n",
        "Para sumar dos matrices se debe verificar que el orden de estas sean iguales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnpRzgg9kTb"
      },
      "source": [
        "#2. Armado del ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4z5eBuU9pRy"
      },
      "source": [
        "##2.1 Armado del ambiente en CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dDFvvnVFEQI"
      },
      "source": [
        "No se requiere la ejecucion previa de algun comando"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCdvhcwu9vXy"
      },
      "source": [
        "##2.1 Armado del ambiente en GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SUH5e0UsqT-"
      },
      "source": [
        "1. Ir a Entornto de ejecucion -> Cambiar tipo de entorno de ejecucion y seleccionar la opcion GPU.\n",
        "2. Se requiere la instalación del modulo de Cuda para Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JspUFpTXjjFC",
        "outputId": "f931ebd4-a91d-4c4c-8923-d90418504be3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 9.2MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=621146 sha256=873b09dd6b3609a0738433e6fdf6549bf2f6f3b834feb39642d526f014af3e5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=69ac9e60bd1c1674e6bcd5d8bbe4868231d5c87d559ddb09844f20af1cb3dd63\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUCDxn8-9ywT"
      },
      "source": [
        "#3. Desarrollo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDJ5YrXp91Jy"
      },
      "source": [
        "##3.1 Desarrollo en CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnWXJbo6BePp",
        "outputId": "7817a00d-59ed-48a1-a8d6-2ba0df351577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "tamMatriz =  -1#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "import numpy\n",
        "import time\n",
        "import sys\n",
        "\n",
        "tiempoTotal = time.time() * 1000\n",
        "try: \n",
        "  matriz_A = numpy.random.randint(5000, size=(tamMatriz, tamMatriz))\n",
        "  matriz_A = matriz_A.astype(numpy.int32())\n",
        "  matriz_B = numpy.random.randint(5000, size=(tamMatriz, tamMatriz))\n",
        "  matriz_B = matriz_B.astype(numpy.int32())\n",
        "except Exception:\n",
        "  sys.exit(\"El tamaño no puede ser negativo\")\n",
        "\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Matriz A:\\n\",matriz_A)\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Matriz B:\\n\",matriz_B)\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "tiempoBucle = time.time() * 1000\n",
        "matriz_R = numpy.zeros((tamMatriz, tamMatriz))  \n",
        "matriz_R = matriz_R.astype(numpy.int32())\n",
        "\n",
        "for i in range (0, tamMatriz):\n",
        "  for j in range(0, tamMatriz):\n",
        "    matriz_R[i][j] = matriz_A[i][j] + matriz_B[i][j]\n",
        "\n",
        "print(\"Matriz R:\\n\",matriz_R)\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "tiempoTotal = (time.time() * 1000) - tiempoTotal\n",
        "tiempoBucle = (time.time() * 1000) - tiempoBucle\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"Tiempo del bucle: \" , tiempoBucle , \"[ms.]\")\n",
        "print(\"Tiempo del total: \" , tiempoTotal , \"[ms.]\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m El tamaño no puede ser negativo\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvdUxO9d93Xa"
      },
      "source": [
        "##3.2 Desarrollo en GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brL5K2Qjjpoo",
        "outputId": "89245bed-32ab-4889-b3eb-2538738b1faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "tamMatriz =  -0#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "import time\n",
        "\n",
        "import numpy\n",
        "import sys\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "tiempoTotal = (time.time()*1000)\n",
        "\n",
        "try: \n",
        "  matriz_A_cpu = numpy.random.randint(5000, size=(tamMatriz, tamMatriz))\n",
        "  matriz_A_cpu = matriz_A_cpu.astype(numpy.int32())\n",
        "  matriz_B_cpu = numpy.random.randint(5000, size=(tamMatriz, tamMatriz))\n",
        "  matriz_B_cpu = matriz_B_cpu.astype(numpy.int32())\n",
        "except Exception:\n",
        "  sys.exit(\"El tamaño de la matriz no puede ser negativo\")\n",
        "\n",
        "try:  \n",
        "  matriz_R_cpu = numpy.zeros((tamMatriz, tamMatriz)) \n",
        "  matriz_R_cpu = matriz_R_cpu.astype(numpy.int32()) \n",
        "  matriz_A_gpu = cuda.mem_alloc(matriz_A_cpu.nbytes)\n",
        "  matriz_B_gpu = cuda.mem_alloc(matriz_B_cpu.nbytes)\n",
        "  matriz_R_gpu = cuda.mem_alloc(matriz_R_cpu.nbytes)\n",
        "  cuda.memcpy_htod(matriz_A_gpu, matriz_A_cpu)\n",
        "  cuda.memcpy_htod(matriz_B_gpu, matriz_B_cpu)\n",
        "  cuda.memcpy_htod(matriz_R_gpu, matriz_R_cpu)\n",
        "except Exception:\n",
        "  sys.exit(\"Error de asignacion de memoria para gpu\")\n",
        "\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Matriz A:\\n\",matriz_A_cpu)\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Matriz B:\\n\",matriz_B_cpu)\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void matrixMultiplicationKernel(float* A, float* B, float* R,\n",
        "                                           int N\n",
        "                                           ) {\n",
        "\n",
        "    int x = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "    int y = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\n",
        "    if(y < N){\n",
        "      R[x+ y*N] = A[x+ y*N]  +  B[x+ y*N];\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "kernel = module.get_function(\"matrixMultiplicationKernel\")\n",
        "\n",
        "dim_hilo_x = 16\n",
        "dim_bloque_x = numpy.int( (tamMatriz + dim_hilo_x-1) / dim_hilo_x )\n",
        "\n",
        "dim_hilo_y = 16\n",
        "dim_bloque_y = numpy.int( (tamMatriz + dim_hilo_y-1) / dim_hilo_y )\n",
        "\n",
        "print( \"Thread: [\", dim_hilo_x, \",\", dim_hilo_y, \" ], Bloque : [\", dim_bloque_x, \",\", dim_bloque_y, \"]\" )\n",
        "print( \"Total de Thread: [\", dim_hilo_x*dim_bloque_x, \",\", dim_hilo_y*dim_bloque_y, \" ]\", \" = \", dim_hilo_x*dim_bloque_x*dim_hilo_y*dim_bloque_y )\n",
        "\n",
        "tiempo_kernel = time.time() * 1000\n",
        "\n",
        "kernel(matriz_A_gpu, matriz_B_gpu, matriz_R_gpu,\n",
        "       numpy.int32(tamMatriz),        \n",
        "       block=( dim_hilo_x, dim_hilo_y, 1), \n",
        "       grid=(dim_bloque_x, dim_bloque_y,1)\n",
        "       )\n",
        "\n",
        "tiempo_kernel = (time.time() *1000) - tiempo_kernel\n",
        "\n",
        "cuda.memcpy_dtoh(matriz_R_cpu, matriz_R_gpu)\n",
        "tiempoTotal = (time.time() * 1000) - tiempoTotal\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Matriz resultado:\\n\",matriz_R_cpu)\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Tiempo TOTAL: \", tiempoTotal, \"[ms]\" )\n",
        "print(\"Tiempo GPU  : \", tiempo_kernel, \"[ms]\" )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Error de asignacion de memoria para gpu\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftAKsvjH953S"
      },
      "source": [
        "#4. Tabla de pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncs8MsOX9_yz"
      },
      "source": [
        "##4.1 Tabla de pasos CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBfp6RFobcGJ"
      },
      "source": [
        "Tabla de ejecucion de forma secuencial\n",
        ">Procesador | Funcion | Detalle\n",
        ">--- | --- | ----\n",
        ">CPU\t|@param              |Lectura del tamaño de matriz.\n",
        ">CPU\t|import              |Se importa los diferentes modulos a utilizar.\n",
        ">CPU\t|tiempoTotal         |Se obtiene el tiempo actual para futuras mediciones.\n",
        ">CPU\t|numpy.random.randint|Inicializacion de matrices.\n",
        ">CPU\t|tiempoBucle\t       |Se toma el tiempo inicial del algoritmo presentado.\n",
        ">CPU\t|for…\tfor            |Se realiza el algoritmo.\n",
        ">CPU\t|tiempoBucle\t       |Toma el tiempo final del algoritmo presentado.\n",
        ">CPU\t|tiempoTotal\t       |Toma el tiempo final de la ejecucion.\n",
        ">CPU\t|print()\t           |Se informan los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAtzQqbF-FGT"
      },
      "source": [
        "##4.1 Tabla de pasos GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJGwWEidbdqT"
      },
      "source": [
        "Tabla de ejecucion en multiples hilos de ejecucion\n",
        ">Procesador | Funcion | Detalle\n",
        ">--- | --- | ----\n",
        ">CPU\t|@param              |Lectura del tamaño de matriz.\n",
        ">CPU\t|import              |Se importa los diferentes modulos a utilizar.\n",
        ">CPU\t|tiempoTotal         |Se obtiene el tiempo actual para futuras mediciones.\n",
        ">CPU\t|numpy.random.randint|Inicializacion de matrices.\n",
        ">CPU\t|numpy.zeros         |Inicializacion de matriz de resultado.\n",
        ">**GPU**  |cuda.mem_alloc        |Reserva de memoria de GPU.\n",
        ">**GPU**  |cuda.memcpy_htod      |Copia de memoria de CPU a GPU.\n",
        ">CPU\t|SourceModule        |Definición de código del kernel.\n",
        ">CPU\t|module.get_function        |Generación de función del Kernel de GPU.\n",
        ">CPU\t|dim_hilo_x, dim_hilo_y\t    | Calcula las dimensiones para la ejecuciòn de 2D.\n",
        ">CPU\t|tiempo_kernel\t       |Toma el tiempo inicial del algoritmo presentado.\n",
        ">**GPU**\t|kernel()            |Ejecución del kernel\n",
        ">CPU\t|tiempo_kernel\t       |Toma el tiempo final del algoritmo presentado.\n",
        ">CPU\t|tiempoTotal\t       |Toma el tiempo final de la ejecucion.\n",
        ">CPU\t|print()\t           |Se informan los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDk8h3X0-I2C"
      },
      "source": [
        "#5. Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1IpZ52s6X_I"
      },
      "source": [
        "El algoritmo no presenta mucha dificultad, lo interesante es que el primer algoritmo posee una complejidad O(N^2) y su rendimiento empeorara a medida que las dimensiones de la matriz sean mayores. Con la implementación paralela aumenta la eficiencia frente a la ejecución secuencial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0xYuckC1342"
      },
      "source": [
        "#6. Bibliografía"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au-dr5c116eU"
      },
      "source": [
        "[1].Suma de matrices [matrices](https://economipedia.com/definiciones/suma-de-matrices.html)"
      ]
    }
  ]
}